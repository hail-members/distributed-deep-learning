{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5GgZqEemuqqxdoCcHFxfd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hail-members/distributed-deep-learning/blob/main/Parallel%20computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXG2gmmmHnA5",
        "outputId": "32ec838f-0ef4-4847-de7a-49a834b27ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing performance for 200x200 matrices:\n",
            "Original order time: 7.022731 seconds\n",
            "Reordered time: 5.456274 seconds\n",
            "Speedup: 1.29x\n",
            "\n",
            "Verifying correctness:\n",
            "Original vs NumPy: True\n",
            "Reordered vs NumPy: True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def matmul_original(A, B):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def matmul_reordered(A, B):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(C.shape[0]):\n",
        "        for k in range(A.shape[1]):\n",
        "            for j in range(C.shape[1]):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def compare_performance(A, B):\n",
        "    # Original order (i-j-k)\n",
        "    start_time = time.time()\n",
        "    matmul_original(A, B)\n",
        "    original_time = time.time() - start_time\n",
        "\n",
        "    # Reordered (i-k-j)\n",
        "    start_time = time.time()\n",
        "    matmul_reordered(A, B)\n",
        "    reordered_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Original order time: {original_time:.6f} seconds\")\n",
        "    print(f\"Reordered time: {reordered_time:.6f} seconds\")\n",
        "    print(f\"Speedup: {original_time / reordered_time:.2f}x\")\n",
        "\n",
        "# Test the performance\n",
        "if __name__ == \"__main__\":\n",
        "    # Create random matrices\n",
        "    A = np.random.rand(200, 200)\n",
        "    B = np.random.rand(200, 200)\n",
        "\n",
        "    print(\"Comparing performance for 200x200 matrices:\")\n",
        "    compare_performance(A, B)\n",
        "\n",
        "    # Verify correctness\n",
        "    C_original = matmul_original(A, B)\n",
        "    C_reordered = matmul_reordered(A, B)\n",
        "    C_numpy = np.dot(A, B)\n",
        "\n",
        "    print(\"\\nVerifying correctness:\")\n",
        "    print(f\"Original vs NumPy: {np.allclose(C_original, C_numpy)}\")\n",
        "    print(f\"Reordered vs NumPy: {np.allclose(C_reordered, C_numpy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def matmul_original(A, B):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def matmul_tiled(A, B, tile_size=50):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(0, C.shape[0], tile_size):\n",
        "        for j in range(0, C.shape[1], tile_size):\n",
        "            for k in range(0, A.shape[1], tile_size):\n",
        "                # 각 타일에 대해 행렬 곱 수행\n",
        "                for ii in range(i, min(i + tile_size, C.shape[0])):\n",
        "                    for jj in range(j, min(j + tile_size, C.shape[1])):\n",
        "                        for kk in range(k, min(k + tile_size, A.shape[1])):\n",
        "                            C[ii, jj] += A[ii, kk] * B[kk, jj]\n",
        "    return C\n",
        "\n",
        "def compare_performance(A, B):\n",
        "    # Original version\n",
        "    start_time = time.time()\n",
        "    matmul_original(A, B)\n",
        "    original_time = time.time() - start_time\n",
        "\n",
        "    # Tiled version\n",
        "    start_time = time.time()\n",
        "    matmul_tiled(A, B)\n",
        "    tiled_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Original version time: {original_time:.6f} seconds\")\n",
        "    print(f\"Tiled version time: {tiled_time:.6f} seconds\")\n",
        "    print(f\"Speedup: {original_time / tiled_time:.2f}x\")\n",
        "\n",
        "# Test the performance\n",
        "if __name__ == \"__main__\":\n",
        "    # Create random matrices\n",
        "    A = np.random.rand(200, 200)\n",
        "    B = np.random.rand(200, 200)\n",
        "\n",
        "    print(\"Comparing performance for 500x500 matrices:\")\n",
        "    compare_performance(A, B)\n",
        "\n",
        "    # Verify correctness\n",
        "    C_original = matmul_original(A, B)\n",
        "    C_tiled = matmul_tiled(A, B)\n",
        "    C_numpy = np.dot(A, B)\n",
        "\n",
        "    print(\"\\nVerifying correctness:\")\n",
        "    print(f\"Original vs NumPy: {np.allclose(C_original, C_numpy)}\")\n",
        "    print(f\"Tiled vs NumPy: {np.allclose(C_tiled, C_numpy)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41944uNOIPUM",
        "outputId": "56387fd1-9db4-487e-d7d3-3a29a6b178e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing performance for 500x500 matrices:\n",
            "Original version time: 7.321975 seconds\n",
            "Tiled version time: 5.673241 seconds\n",
            "Speedup: 1.29x\n",
            "\n",
            "Verifying correctness:\n",
            "Original vs NumPy: True\n",
            "Tiled vs NumPy: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def matmul_original(A, B):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def matmul_tiled(A, B, tile_size=100):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(0, C.shape[0], tile_size):\n",
        "        for j in range(0, C.shape[1], tile_size):\n",
        "            for k in range(0, A.shape[1], tile_size):\n",
        "                for ii in range(i, min(i + tile_size, C.shape[0])):\n",
        "                    for jj in range(j, min(j + tile_size, C.shape[1])):\n",
        "                        for kk in range(k, min(k + tile_size, A.shape[1])):\n",
        "                            C[ii, jj] += A[ii, kk] * B[kk, jj]\n",
        "    return C\n",
        "\n",
        "def matmul_tiled_unrolled(A, B, tile_size=100, unroll_factor=10):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(0, C.shape[0], tile_size):\n",
        "        for j in range(0, C.shape[1], tile_size):\n",
        "            for k in range(0, A.shape[1], tile_size):\n",
        "                for ii in range(i, min(i + tile_size, C.shape[0])):\n",
        "                    for jj in range(j, min(j + tile_size, C.shape[1])):\n",
        "                        kk = k\n",
        "                        while kk < min(k + tile_size, A.shape[1]) - unroll_factor + 1:\n",
        "                            C[ii, jj] += A[ii, kk] * B[kk, jj]\n",
        "                            C[ii, jj] += A[ii, kk+1] * B[kk+1, jj]\n",
        "                            C[ii, jj] += A[ii, kk+2] * B[kk+2, jj]\n",
        "                            C[ii, jj] += A[ii, kk+3] * B[kk+3, jj]\n",
        "                            kk += unroll_factor\n",
        "                        # Handle remaining elements\n",
        "                        while kk < min(k + tile_size, A.shape[1]):\n",
        "                            C[ii, jj] += A[ii, kk] * B[kk, jj]\n",
        "                            kk += 1\n",
        "    return C\n",
        "\n",
        "def compare_performance(A, B):\n",
        "    # Original version\n",
        "    start_time = time.time()\n",
        "    C_original = matmul_original(A, B)\n",
        "    original_time = time.time() - start_time\n",
        "\n",
        "    # Tiled version\n",
        "    start_time = time.time()\n",
        "    C_tiled = matmul_tiled(A, B)\n",
        "    tiled_time = time.time() - start_time\n",
        "\n",
        "    # Tiled and unrolled version\n",
        "    start_time = time.time()\n",
        "    C_tiled_unrolled = matmul_tiled_unrolled(A, B)\n",
        "    tiled_unrolled_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Original version time: {original_time:.6f} seconds\")\n",
        "    print(f\"Tiled version time: {tiled_time:.6f} seconds\")\n",
        "    print(f\"Tiled and unrolled version time: {tiled_unrolled_time:.6f} seconds\")\n",
        "    print(f\"Speedup (Tiled vs Original): {original_time / tiled_time:.2f}x\")\n",
        "    print(f\"Speedup (Tiled+Unrolled vs Original): {original_time / tiled_unrolled_time:.2f}x\")\n",
        "\n",
        "    # Verify correctness\n",
        "    C_numpy = np.dot(A, B)\n",
        "    print(\"\\nVerifying correctness:\")\n",
        "    print(f\"Original vs NumPy: {np.allclose(C_original, C_numpy)}\")\n",
        "    print(f\"Tiled vs NumPy: {np.allclose(C_tiled, C_numpy)}\")\n",
        "    print(f\"Tiled+Unrolled vs NumPy: {np.allclose(C_tiled_unrolled, C_numpy)}\")\n",
        "\n",
        "# Test the performance\n",
        "if __name__ == \"__main__\":\n",
        "    # Create random matrices\n",
        "    A = np.random.rand(200, 200)\n",
        "    B = np.random.rand(200, 200)\n",
        "\n",
        "    print(\"Comparing performance for 200x200 matrices:\")\n",
        "    compare_performance(A, B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frt2UYAGL17K",
        "outputId": "883b3b5c-328a-4c5e-a061-415d5cd519e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing performance for 200x200 matrices:\n",
            "Original version time: 6.962770 seconds\n",
            "Tiled version time: 5.540080 seconds\n",
            "Tiled and unrolled version time: 3.924790 seconds\n",
            "Speedup (Tiled vs Original): 1.26x\n",
            "Speedup (Tiled+Unrolled vs Original): 1.77x\n",
            "\n",
            "Verifying correctness:\n",
            "Original vs NumPy: True\n",
            "Tiled vs NumPy: True\n",
            "Tiled+Unrolled vs NumPy: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 1000000\n",
        "A = np.random.rand(N)\n",
        "B = np.random.rand(N)\n",
        "\n",
        "# SISD\n",
        "start_sisd = time.time()\n",
        "C_sisd = np.zeros(N)\n",
        "for i in range(N):\n",
        "    C_sisd[i] = A[i] * B[i]\n",
        "end_sisd = time.time()\n",
        "sisd_time = end_sisd - start_sisd\n",
        "\n",
        "# Vectorized data\n",
        "start_vectorized = time.time()\n",
        "C_vectorized = A * B\n",
        "end_vectorized = time.time()\n",
        "vectorized_time = end_vectorized - start_vectorized\n",
        "\n",
        "# Speedup calculation\n",
        "speedup = sisd_time / vectorized_time\n",
        "\n",
        "\n",
        "print(f\"Original (SISD) version time: {sisd_time:.6f} seconds\")\n",
        "print(f\"Vectorized version time: {vectorized_time:.6f} seconds\")\n",
        "print(f\"Speedup: {sisd_time / vectorized_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AcAkNOIiW2-",
        "outputId": "b187b3d4-9386-4bb7-8d79-7757fdbcbbbb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original (SISD) version time: 0.513688 seconds\n",
            "Vectorized version time: 0.007482 seconds\n",
            "Speedup: 68.65x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "# Matrix multiplication without multiprocessing\n",
        "def matrix_multiply(A, B):\n",
        "    N = len(A)\n",
        "    C = [[0] * N for _ in range(N)]\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            for k in range(N):\n",
        "                C[i][j] += A[i][k] * B[k][j]\n",
        "    return C\n",
        "\n",
        "# Matrix multiplication with multiprocessing\n",
        "def parallel_multiply_row(args):\n",
        "    i, A, B = args\n",
        "    N = len(A)\n",
        "    row = [0] * N\n",
        "    for j in range(N):\n",
        "        for k in range(N):\n",
        "            row[j] += A[i][k] * B[k][j]\n",
        "    return row\n",
        "\n",
        "def matrix_multiply_parallel(A, B, num_processes=4):\n",
        "    N = len(A)\n",
        "    pool = Pool(processes=num_processes)\n",
        "    result = pool.map(parallel_multiply_row, [(i, A, B) for i in range(N)])\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return result\n",
        "\n",
        "# Test function to compare times\n",
        "def compare_times(N=100):\n",
        "    # Create two NxN matrices filled with random integers\n",
        "    A = [[np.random.randint(0, 10) for _ in range(N)] for _ in range(N)]\n",
        "    B = [[np.random.randint(0, 10) for _ in range(N)] for _ in range(N)]\n",
        "\n",
        "    # Without multiprocessing\n",
        "    start = time.time()\n",
        "    C_single = matrix_multiply(A, B)\n",
        "    end = time.time()\n",
        "    single_time = end - start\n",
        "\n",
        "    # With multiprocessing\n",
        "    start = time.time()\n",
        "    C_parallel = matrix_multiply_parallel(A, B)\n",
        "    end = time.time()\n",
        "    parallel_time = end - start\n",
        "\n",
        "    # With numpy\n",
        "    A_np = np.array(A)\n",
        "    B_np = np.array(B)\n",
        "    start = time.time()\n",
        "    C_np = np.dot(A_np, B_np)\n",
        "    end = time.time()\n",
        "    numpy_time = end - start\n",
        "\n",
        "    return single_time, parallel_time, numpy_time\n",
        "\n",
        "single_time_reduced, parallel_time_reduced, numpy_time_reduced = compare_times(N=100)\n",
        "\n",
        "# Calculate speedup for reduced matrix size\n",
        "parallel_speedup_reduced = single_time_reduced / parallel_time_reduced\n",
        "numpy_speedup_reduced = single_time_reduced / numpy_time_reduced\n",
        "\n",
        "print(f\"Original version time: {single_time_reduced:.6f} seconds\")\n",
        "print(f\"Multithreading version time: {parallel_time_reduced:.6f} seconds\")\n",
        "print(f\"Speedup: {single_time_reduced / parallel_time_reduced:.2f}x\")\n",
        "\n",
        "print(f\"Numpy version time: {numpy_time_reduced:.6f} seconds\")\n",
        "print(f\"Numpy Speedup: {single_time_reduced / numpy_time_reduced:.2f}x\")\n",
        "\n",
        "\n",
        "# matrix size to 500x500 for feasible computation time\n",
        "single_time_reduced, parallel_time_reduced, numpy_time_reduced = compare_times(N=500)\n",
        "\n",
        "print(f\"Original version time: {single_time_reduced:.6f} seconds\")\n",
        "print(f\"Multithreading version time: {parallel_time_reduced:.6f} seconds\")\n",
        "print(f\"Speedup: {single_time_reduced / parallel_time_reduced:.2f}x\")\n",
        "\n",
        "print(f\"Numpy version time: {numpy_time_reduced:.6f} seconds\")\n",
        "print(f\"Numpy Speedup: {single_time_reduced / numpy_time_reduced:.2f}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIERyARii_xc",
        "outputId": "af91d7f6-3570-499f-fcfa-264c61ecea9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original version time: 0.219301 seconds\n",
            "Multithreading version time: 0.293322 seconds\n",
            "Speedup: 0.75x\n",
            "Numpy version time: 0.001040 seconds\n",
            "Numpy Speedup: 210.87x\n",
            "Original version time: 33.256274 seconds\n",
            "Multithreading version time: 28.833416 seconds\n",
            "Speedup: 1.15x\n",
            "Numpy version time: 0.171654 seconds\n",
            "Numpy Speedup: 193.74x\n"
          ]
        }
      ]
    }
  ]
}