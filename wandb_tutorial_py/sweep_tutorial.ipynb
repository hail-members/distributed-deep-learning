{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e472600",
   "metadata": {},
   "source": [
    "ÏïÑÎûò Îëò Ï§ë ÌïòÎÇò Ïã§Ìñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df24550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: sweep_bayes.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep with ID: \u001b[33muibe4sdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/uibe4sdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent dongjaekim/distributed-deep-learning-wandb_tutorial_py/uibe4sdf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb sweep sweep_bayes.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a00ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2025-11-06 14:32:17,700 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2025-11-06 14:32:18,330 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 14:32:18,330 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 4\n",
      "\thidden_size: 256\n",
      "\tlearning_rate: 0.01417135453006273\n",
      "2025-11-06 14:32:18,331 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=4 --hidden_size=256 --learning_rate=0.01417135453006273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run qrqtgsfk (0.0s)\n",
      "2025-11-06 14:32:23,338 - wandb.wandb_agent - INFO - Running runs: ['qrqtgsfk']\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run qrqtgsfk (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run qrqtgsfk (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run qrqtgsfk (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_143222-qrqtgsfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtough-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/uibe4sdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/qrqtgsfk\u001b[0m\n",
      "Epoch 0: Test Loss=0.2934, Acc=92.23%\n",
      "Epoch 1: Test Loss=0.3196, Acc=91.80%\n",
      "Epoch 2: Test Loss=0.2777, Acc=93.39%\n",
      "Epoch 3: Test Loss=0.2471, Acc=94.03%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mtough-sweep-1\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/qrqtgsfk\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_143222-qrqtgsfk/logs\u001b[0m\n",
      "2025-11-06 14:32:59,990 - wandb.wandb_agent - INFO - Cleaning up finished run: qrqtgsfk\n",
      "2025-11-06 14:33:01,131 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 14:33:01,131 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 7\n",
      "\thidden_size: 128\n",
      "\tlearning_rate: 0.016927866756448903\n",
      "2025-11-06 14:33:01,132 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=7 --hidden_size=128 --learning_rate=0.016927866756448903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 21p1qipj (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_143305-21p1qipj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmagic-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/uibe4sdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/21p1qipj\u001b[0m\n",
      "2025-11-06 14:33:06,139 - wandb.wandb_agent - INFO - Running runs: ['21p1qipj']\n",
      "Epoch 0: Test Loss=0.2672, Acc=92.45%\n",
      "Epoch 1: Test Loss=0.3007, Acc=93.15%\n",
      "Epoch 2: Test Loss=0.2512, Acc=94.52%\n",
      "Epoch 3: Test Loss=0.2952, Acc=92.59%\n",
      "Epoch 4: Test Loss=0.2861, Acc=94.06%\n",
      "Epoch 5: Test Loss=0.3120, Acc=93.51%\n",
      "Epoch 6: Test Loss=0.3162, Acc=94.30%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mmagic-sweep-2\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/21p1qipj\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_143305-21p1qipj/logs\u001b[0m\n",
      "2025-11-06 14:34:03,719 - wandb.wandb_agent - INFO - Cleaning up finished run: 21p1qipj\n",
      "2025-11-06 14:34:04,342 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 14:34:04,342 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 256\n",
      "\tlearning_rate: 0.011707386007124908\n",
      "2025-11-06 14:34:04,342 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=256 --learning_rate=0.011707386007124908\n"
     ]
    }
   ],
   "source": [
    "# [YOUR_USERNAME]/[PROJECT_NAME]/abc123de Î∂ÄÎ∂ÑÏùÄ ÏúÑÏóêÏÑú Î∞õÏùÄ IDÎ°ú ÎåÄÏ≤¥\n",
    "!wandb agent --count=5 dongjaekim/distributed-deep-learning-wandb_tutorial_py/uibe4sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710783e1",
   "metadata": {},
   "source": [
    "ÎòêÎäî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3489d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: sweep_grid.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep with ID: \u001b[33mtuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent dongjaekim/distributed-deep-learning-wandb_tutorial_py/tuwy6rzz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb sweep sweep_grid.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86919a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2025-11-06 03:53:15,930 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2025-11-06 03:53:16,275 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:53:16,275 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 32\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:53:16,277 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=32 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run eeda08dn (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run eeda08dn (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run eeda08dn (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035320-eeda08dn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrosy-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/eeda08dn\u001b[0m\n",
      "2025-11-06 03:53:21,284 - wandb.wandb_agent - INFO - Running runs: ['eeda08dn']\n",
      "Epoch 0: Test Loss=0.2260, Acc=93.21%\n",
      "Epoch 1: Test Loss=0.2153, Acc=94.23%\n",
      "Epoch 2: Test Loss=0.2223, Acc=94.23%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mrosy-sweep-1\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/eeda08dn\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035320-eeda08dn/logs\u001b[0m\n",
      "2025-11-06 03:53:47,342 - wandb.wandb_agent - INFO - Cleaning up finished run: eeda08dn\n",
      "2025-11-06 03:53:47,772 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:53:47,772 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 32\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 03:53:47,773 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=32 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run rpdx8khf (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035351-rpdx8khf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeachy-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/rpdx8khf\u001b[0m\n",
      "2025-11-06 03:53:52,780 - wandb.wandb_agent - INFO - Running runs: ['rpdx8khf']\n",
      "Epoch 0: Test Loss=0.2088, Acc=93.75%\n",
      "Epoch 1: Test Loss=0.1689, Acc=95.07%\n",
      "Epoch 2: Test Loss=0.1473, Acc=95.69%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mpeachy-sweep-2\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/rpdx8khf\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035351-rpdx8khf/logs\u001b[0m\n",
      "2025-11-06 03:54:18,880 - wandb.wandb_agent - INFO - Cleaning up finished run: rpdx8khf\n",
      "2025-11-06 03:54:19,192 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:54:19,192 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 64\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:54:19,193 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=64 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run 5o0r7he4 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 5o0r7he4 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 5o0r7he4 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035422-5o0r7he4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglorious-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/5o0r7he4\u001b[0m\n",
      "2025-11-06 03:54:24,198 - wandb.wandb_agent - INFO - Running runs: ['5o0r7he4']\n",
      "Epoch 0: Test Loss=0.2167, Acc=94.06%\n",
      "Epoch 1: Test Loss=0.1990, Acc=94.50%\n",
      "Epoch 2: Test Loss=0.1989, Acc=94.96%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mglorious-sweep-3\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/5o0r7he4\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035422-5o0r7he4/logs\u001b[0m\n",
      "2025-11-06 03:54:50,241 - wandb.wandb_agent - INFO - Cleaning up finished run: 5o0r7he4\n",
      "2025-11-06 03:54:50,664 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:54:50,664 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 64\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 03:54:50,665 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=64 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run b55gl8md (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run b55gl8md (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run b55gl8md (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035454-b55gl8md\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeach-sweep-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/b55gl8md\u001b[0m\n",
      "2025-11-06 03:54:55,668 - wandb.wandb_agent - INFO - Running runs: ['b55gl8md']\n",
      "Epoch 0: Test Loss=0.1821, Acc=94.51%\n",
      "Epoch 1: Test Loss=0.1208, Acc=96.28%\n",
      "Epoch 2: Test Loss=0.1072, Acc=96.82%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mpeach-sweep-4\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/b55gl8md\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035454-b55gl8md/logs\u001b[0m\n",
      "2025-11-06 03:55:21,741 - wandb.wandb_agent - INFO - Cleaning up finished run: b55gl8md\n",
      "2025-11-06 03:55:22,114 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:55:22,115 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 128\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:55:22,116 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=128 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run zwe1udso (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run zwe1udso (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035525-zwe1udso\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-sweep-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/zwe1udso\u001b[0m\n",
      "2025-11-06 03:55:27,122 - wandb.wandb_agent - INFO - Running runs: ['zwe1udso']\n",
      "Epoch 0: Test Loss=0.2084, Acc=94.18%\n",
      "Epoch 1: Test Loss=0.2139, Acc=94.74%\n",
      "Epoch 2: Test Loss=0.2283, Acc=94.18%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33miconic-sweep-5\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/zwe1udso\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035525-zwe1udso/logs\u001b[0m\n",
      "2025-11-06 03:55:53,207 - wandb.wandb_agent - INFO - Cleaning up finished run: zwe1udso\n",
      "2025-11-06 03:55:53,616 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:55:53,616 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 3\n",
      "\thidden_size: 128\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 03:55:53,617 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=3 --hidden_size=128 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run ckkc39qt (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ckkc39qt (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035557-ckkc39qt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msummer-sweep-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ckkc39qt\u001b[0m\n",
      "2025-11-06 03:55:58,623 - wandb.wandb_agent - INFO - Running runs: ['ckkc39qt']\n",
      "Epoch 0: Test Loss=0.1317, Acc=96.10%\n",
      "Epoch 1: Test Loss=0.0943, Acc=97.09%\n",
      "Epoch 2: Test Loss=0.0795, Acc=97.64%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33msummer-sweep-6\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ckkc39qt\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035557-ckkc39qt/logs\u001b[0m\n",
      "2025-11-06 03:56:24,729 - wandb.wandb_agent - INFO - Cleaning up finished run: ckkc39qt\n",
      "2025-11-06 03:56:25,085 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:56:25,085 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 32\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:56:25,086 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=32 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run ssmx7vpm (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ssmx7vpm (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035628-ssmx7vpm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlemon-sweep-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ssmx7vpm\u001b[0m\n",
      "2025-11-06 03:56:30,088 - wandb.wandb_agent - INFO - Running runs: ['ssmx7vpm']\n",
      "Epoch 0: Test Loss=0.2347, Acc=92.79%\n",
      "Epoch 1: Test Loss=0.2295, Acc=93.41%\n",
      "Epoch 2: Test Loss=0.2301, Acc=93.55%\n",
      "Epoch 3: Test Loss=0.2874, Acc=92.55%\n",
      "Epoch 4: Test Loss=0.2384, Acc=93.35%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mlemon-sweep-7\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ssmx7vpm\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035628-ssmx7vpm/logs\u001b[0m\n",
      "2025-11-06 03:57:11,818 - wandb.wandb_agent - INFO - Cleaning up finished run: ssmx7vpm\n",
      "2025-11-06 03:57:12,163 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:57:12,164 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 32\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 03:57:12,165 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=32 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run ukqgfvsm (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ukqgfvsm (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run ukqgfvsm (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035716-ukqgfvsm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-sweep-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ukqgfvsm\u001b[0m\n",
      "2025-11-06 03:57:17,171 - wandb.wandb_agent - INFO - Running runs: ['ukqgfvsm']\n",
      "Epoch 0: Test Loss=0.2199, Acc=93.31%\n",
      "Epoch 1: Test Loss=0.1633, Acc=94.98%\n",
      "Epoch 2: Test Loss=0.1484, Acc=95.33%\n",
      "Epoch 3: Test Loss=0.1279, Acc=96.07%\n",
      "Epoch 4: Test Loss=0.1229, Acc=96.48%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mgenial-sweep-8\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/ukqgfvsm\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035716-ukqgfvsm/logs\u001b[0m\n",
      "2025-11-06 03:57:58,907 - wandb.wandb_agent - INFO - Cleaning up finished run: ukqgfvsm\n",
      "2025-11-06 03:57:59,278 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:57:59,279 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 64\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:57:59,280 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=64 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run fcza79mx (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run fcza79mx (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run fcza79mx (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035803-fcza79mx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-sweep-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/fcza79mx\u001b[0m\n",
      "2025-11-06 03:58:04,284 - wandb.wandb_agent - INFO - Running runs: ['fcza79mx']\n",
      "Epoch 0: Test Loss=0.1676, Acc=95.02%\n",
      "Epoch 1: Test Loss=0.1805, Acc=95.19%\n",
      "Epoch 2: Test Loss=0.2239, Acc=93.89%\n",
      "Epoch 3: Test Loss=0.2409, Acc=94.69%\n",
      "Epoch 4: Test Loss=0.2027, Acc=95.30%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mbreezy-sweep-9\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/fcza79mx\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035803-fcza79mx/logs\u001b[0m\n",
      "2025-11-06 03:58:46,004 - wandb.wandb_agent - INFO - Cleaning up finished run: fcza79mx\n",
      "2025-11-06 03:58:46,489 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:58:46,489 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 64\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 03:58:46,490 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=64 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run g8skz1z6 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035850-g8skz1z6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnoble-sweep-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/g8skz1z6\u001b[0m\n",
      "2025-11-06 03:58:51,495 - wandb.wandb_agent - INFO - Running runs: ['g8skz1z6']\n",
      "Epoch 0: Test Loss=0.1777, Acc=94.78%\n",
      "Epoch 1: Test Loss=0.1223, Acc=96.09%\n",
      "Epoch 2: Test Loss=0.1036, Acc=96.79%\n",
      "Epoch 3: Test Loss=0.0916, Acc=97.22%\n",
      "Epoch 4: Test Loss=0.0973, Acc=97.16%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mnoble-sweep-10\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/g8skz1z6\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035850-g8skz1z6/logs\u001b[0m\n",
      "2025-11-06 03:59:33,187 - wandb.wandb_agent - INFO - Cleaning up finished run: g8skz1z6\n",
      "2025-11-06 03:59:33,702 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 03:59:33,702 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 128\n",
      "\tlearning_rate: 0.01\n",
      "2025-11-06 03:59:33,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=128 --learning_rate=0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run gnjr706f (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run gnjr706f (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_035937-gnjr706f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33molive-sweep-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/gnjr706f\u001b[0m\n",
      "2025-11-06 03:59:38,710 - wandb.wandb_agent - INFO - Running runs: ['gnjr706f']\n",
      "Epoch 0: Test Loss=0.2331, Acc=93.56%\n",
      "Epoch 1: Test Loss=0.1647, Acc=95.31%\n",
      "Epoch 2: Test Loss=0.2126, Acc=94.30%\n",
      "Epoch 3: Test Loss=0.2099, Acc=94.86%\n",
      "Epoch 4: Test Loss=0.2052, Acc=95.48%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33molive-sweep-11\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/gnjr706f\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_035937-gnjr706f/logs\u001b[0m\n",
      "2025-11-06 04:00:20,416 - wandb.wandb_agent - INFO - Cleaning up finished run: gnjr706f\n",
      "2025-11-06 04:00:20,803 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2025-11-06 04:00:20,804 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tepochs: 5\n",
      "\thidden_size: 128\n",
      "\tlearning_rate: 0.001\n",
      "2025-11-06 04:00:20,805 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python sweeptrain.py --epochs=5 --hidden_size=128 --learning_rate=0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongjaekim\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run hknkuv13 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/hail/HDD/dk/distributed-deep-learning/wandb_tutorial_py/wandb/run-20251106_040024-hknkuv13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcomic-sweep-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/sweeps/tuwy6rzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/hknkuv13\u001b[0m\n",
      "2025-11-06 04:00:25,811 - wandb.wandb_agent - INFO - Running runs: ['hknkuv13']\n",
      "Epoch 0: Test Loss=0.1311, Acc=96.20%\n",
      "Epoch 1: Test Loss=0.1021, Acc=96.76%\n",
      "Epoch 2: Test Loss=0.0985, Acc=96.94%\n",
      "Epoch 3: Test Loss=0.0766, Acc=97.67%\n",
      "Epoch 4: Test Loss=0.0903, Acc=97.24%\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mcomic-sweep-12\u001b[0m at: \u001b[34mhttps://wandb.ai/dongjaekim/distributed-deep-learning-wandb_tutorial_py/runs/hknkuv13\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251106_040024-hknkuv13/logs\u001b[0m\n",
      "2025-11-06 04:01:07,523 - wandb.wandb_agent - INFO - Cleaning up finished run: hknkuv13\n",
      "2025-11-06 04:01:07,918 - wandb.wandb_agent - INFO - Agent received command: exit\n",
      "2025-11-06 04:01:07,918 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
     ]
    }
   ],
   "source": [
    "# [YOUR_USERNAME]/[PROJECT_NAME]/abc123de Î∂ÄÎ∂ÑÏùÄ ÏúÑÏóêÏÑú Î∞õÏùÄ IDÎ°ú ÎåÄÏ≤¥\n",
    "!wandb agent dongjaekim/distributed-deep-learning-wandb_tutorial_py/tuwy6rzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debf0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
