{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hail-members/distributed-deep-learning/blob/main/JAX_FLAX/2.JAX2JIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4563125a",
      "metadata": {
        "id": "4563125a"
      },
      "source": [
        "# JAX의 JIT 컴파일\n",
        "\n",
        "jax가 순수함수를 그렇게 고집하는건 JIT (just-in-time) 컴파일을 하기 위해서입니다. JIT 컴파일은 함수를 실행하기 전에 최적화된 기계어 코드로 변환하여 실행 속도를 크게 향상시키는 역할을 합니다. 그냥 python은 인터프리터 언어이기 때문에... 그 라인에 도착해서 하나씩 컴파일 하고 실행하고 잊는... 방식을 반복하지만\n",
        "\n",
        "JAX는 순수함수만을 대상으로 JIT 컴파일을 수행할 수 있기 때문에, 함수가 외부 상태에 의존하지 않고 입력에만 의존하도록 설계해야 합니다.\n",
        "\n",
        "함수를 쓰는 방식부터 - jit 데코레이터를 쓰는 방식(더 일반적인 방식)으로 봅시다.\n",
        "jaxpr 은 jax expression 이라는 말로 컴파일된 형태를 의미합니다. 이렇게 변경시켜주는 것을 jax.make_jaxpr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd932920",
      "metadata": {
        "id": "cd932920",
        "outputId": "4d152afd-bb0f-4e76-fa0b-e9f41dcec86f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:f32[]\u001b[39m b\u001b[35m:f32[]\u001b[39m. \u001b[34;1mlet\n",
            "    \u001b[39;22mc\u001b[35m:f32[]\u001b[39m = mul a b\n",
            "    d\u001b[35m:f32[]\u001b[39m = add c 2.0:f32[]\n",
            "  \u001b[34;1min \u001b[39;22m(d,) }\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import make_jaxpr\n",
        "\n",
        "def my_function(x, y):\n",
        "  return x * y + 2\n",
        "\n",
        "print(make_jaxpr(my_function)(3., 4.))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0c58ce",
      "metadata": {
        "id": "2a0c58ce"
      },
      "source": [
        "이거 보면 이런식으로 기계어 같아보이는 뭔가가 나옵니다. 이 상태로 컴파일된걸 그냥 쓰는겁니다 람다 함수기 때문에 a,b를 입력으로 넣어주면 그 안에서 연산을 정해진대로 수행합니다.\n",
        "\n",
        "이건 make_jaxpr 을 한 시점에서 결정된겁니다. jaxpr로 결정되면 my_function 을 변경시켜도, make_jaxpr 로 만들어진 jaxpr이 변경되는게 아닙니다.\n",
        "\n",
        "이번엔 순수함수가 아닌 경우 어떻게 되는지 봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8db44a2",
      "metadata": {
        "id": "f8db44a2",
        "outputId": "0254cf19-d2db-4106-efc6-3f86b8c5a9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printed x: JitTracer<~float32[]>\n",
            "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34;1mlet\n",
            "    \u001b[39;22mb\u001b[35m:f32[]\u001b[39m = log a\n",
            "    c\u001b[35m:f32[]\u001b[39m = log 2.0:f32[]\n",
            "    d\u001b[35m:f32[]\u001b[39m = div b c\n",
            "  \u001b[34;1min \u001b[39;22m(d,) }\n"
          ]
        }
      ],
      "source": [
        "def log2_with_print(x):\n",
        "    print(\"printed x:\", x)\n",
        "    ln_x = jnp.log(x)\n",
        "    ln_2 = jnp.log(2.0)\n",
        "    return ln_x / ln_2\n",
        "\n",
        "\n",
        "print(jax.make_jaxpr(log2_with_print)(3.))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e36dff9",
      "metadata": {
        "id": "2e36dff9"
      },
      "source": [
        "이전에 말했던것처럼 print 는 외부와 상호작용 하는 것이기 때문에 순수함수가 아니게됩니다. 보면 여기서 printed x: 라고 되어있는 부분은 {} 안에 들어가 있지 않습니다. 이건 jaxpr에 포함되지 않았다는 뜻입니다. 이렇게 외부로 왔다 갔다 하는 값은 jaxpr에 포함되지 않아서 컴파일이 통하지 않습니다. 그래서 굳이 jax를 썼음에도 함수가 속도가 빨리지지 않는다는 문제가 발생합니다.\n",
        "\n",
        "다음과 같은 함수에서는 어떻게 되는지 확인해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e276139",
      "metadata": {
        "id": "1e276139",
        "outputId": "19772a87-77ef-4620-d786-75072de9b060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:i32[3]\u001b[39m. \u001b[34;1mlet\u001b[39;22m  \u001b[34;1min \u001b[39;22m(a,) }\n"
          ]
        }
      ],
      "source": [
        "def square_if_gt_2(x):\n",
        "    if x.ndim > 2:\n",
        "        return x**2\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "print(make_jaxpr(square_if_gt_2)(jax.numpy.array([1, 2, 3])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1961f19f",
      "metadata": {
        "id": "1961f19f"
      },
      "source": [
        "이전에 설명했던대로 이렇게 조건문이 있는 경우에 정해진 수대로 돌아가는게 아니라 한번 실행됐을때 입력값에 따라서 컴파일이 됩니다.\n",
        "\n",
        "그래서 여기는 3개짜리 어레이가 들어가니까 jaxpr에서도 length 3개짜리 어레이로 컴파일된걸 볼 수 있습니다. 만약에 5개짜리 어레이를 넣으면 어떻게 될까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10b2f406",
      "metadata": {
        "id": "10b2f406",
        "outputId": "f8c14b04-a778-4240-d23b-249a66cf5d2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:i32[5]\u001b[39m. \u001b[34;1mlet\u001b[39;22m  \u001b[34;1min \u001b[39;22m(a,) }\n"
          ]
        }
      ],
      "source": [
        "print(make_jaxpr(square_if_gt_2)(jax.numpy.array([1, 2, 3, 4, 5])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dda95bc",
      "metadata": {
        "id": "2dda95bc"
      },
      "source": [
        "## JIT으로 컴파일하기\n",
        "\n",
        "make_jaxpr 로 jaxpr 을 얻는 것을 봤습니다만, 이는 실제 컴파일을 하는게 아닌 컴파일 됐을때 표현식이 어떻게 되는지를 보여주는 것입니다. 실제로 컴파일을 해서 속도를 올리기 위해서는 JIT 컴파일을 사용해야 합니다.\n",
        "\n",
        "이는 jax.jit 라는 메서드로 구현되어있으며 일반적으로 데코레이터로 사용됩니다. 이걸로 감싸진 함수는 처음 실행될때 jaxpr로 컴파일되고, 이후에는 그 컴파일된 코드를 재사용하게 됩니다.\n",
        "\n",
        "예를 들어 selu라는 활성함수에 대해서 시간을 측정해보고, jit 컴파일을 적용한 경우를 비교해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5844f188",
      "metadata": {
        "id": "5844f188",
        "outputId": "0fb46a50-ed24-452e-8bf8-62fe3b3f26ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.9 ms ± 11.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "def selu(x, alpha=1.67, lambda_=1.05):\n",
        "    return lambda_ * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
        "\n",
        "\n",
        "x = jnp.arange(1000000)\n",
        "%timeit selu(x).block_until_ready()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "84ce4cb8",
      "metadata": {
        "id": "84ce4cb8",
        "outputId": "cfc71918-c65a-4303-c7a2-f3ef411326f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.01 ms ± 805 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "selu_jit = jax.jit(selu)\n",
        "\n",
        "# Warm up\n",
        "selu_jit(x).block_until_ready()\n",
        "\n",
        "%timeit selu_jit(x).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4eb2b4",
      "metadata": {
        "id": "4f4eb2b4"
      },
      "source": [
        "참고로 여기서 %timeit 은 주피터 노트북에서 제공하는 매직커맨드로, 해당 셀의 실행 시간을 측정해주는 것이고 block_until_ready() 는 jax에서 비동기적으로 실행되는 연산이 완료될 때까지 기다리는 함수입니다. torch 에서 cuda sync 맞춰주는걸로 시간 측정한다고 말했던거 기억하시나요? 여기서도 jax가 비동기적으로 연산을 수행하기 때문에, 정확한 시간을 측정하기 위해서는 block_until_ready() 를 호출하여 연산이 완료될 때까지 기다려야 합니다.\n",
        "\n",
        "참고로, jit 의 경우는 selu_jit 을 한번 실행시키고 나서 시간을 측정합니다. 이는 처음 호출될때야 비로소 컴파일을 하기 때문에 그렇습니다. 첫 호출에서 jaxpr 을 만들고 컴파일을 수행한 후, 이후 호출부터는 이미 컴파일된 코드를 사용하게 됩니다. 아까 위에서 보여드린대로 그래서 첫 호출에서 어떤 값을 넣느냐에 따라 컴파일된 코드가 달라질 수 있습니다. (예: length 3짜리 어레이 넣었을때랑 length 5짜리 어레이 넣었을때랑 다름)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b4018f",
      "metadata": {
        "id": "e8b4018f"
      },
      "source": [
        "## 순수함수가 아닌 경우 JIT 컴파일\n",
        "\n",
        "이번에는 순수함수가 아닌 경우에 jit 컴파일을 한번 시도해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0ff05b66",
      "metadata": {
        "id": "0ff05b66",
        "outputId": "c9bbf3a2-37b7-4bcb-c4f0-cad530729e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-2545734610.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2545734610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mf_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 에러 발생.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2545734610.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTracerBoolConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-2545734610.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    if x > 0:\n",
        "        return x\n",
        "    else:\n",
        "        return 2 * x\n",
        "\n",
        "\n",
        "f_jit = jax.jit(f)\n",
        "f_jit(10) # 에러 발생."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "db8a5b3e",
      "metadata": {
        "id": "db8a5b3e",
        "outputId": "a03502a9-a70d-45ff-9d8c-03534bb7dab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function g at /tmp/ipython-input-1346608175.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1346608175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mg_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mg_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 에러 발생.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1346608175.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTracerBoolConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function g at /tmp/ipython-input-1346608175.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ],
      "source": [
        "# 입력 n이 조건에 포함된 while 반복문.\n",
        "\n",
        "def g(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        i += 1\n",
        "    return x + i\n",
        "\n",
        "\n",
        "g_jit = jax.jit(g)\n",
        "g_jit(10, 20) # 에러 발생."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0538dccd",
      "metadata": {
        "id": "0538dccd"
      },
      "source": [
        "위와 같은 예시들은 입력값에 따라서 연산이 달라지기 떄문에 컴파일된 표현식이 달라지게 된다는 문제점이 있어서 제대로 돌아가지 않습니다.\n",
        "\n",
        "컴퓨터구조 와 같은 수업에서 C언어 로 작성된 코드를 컴파일하면 어떤 instructions들로 나오는지 보는 것들을 해본 적이 있을 텐데 (아님 미안) 여기도 비슷합니다.\n",
        "\n",
        "물론 c언어에서는 bne라던가 beq 같은 분기 명령어가 있고 jax.lax.cond 라는 걸 이용해서 조건문을 활용한 코딩을 할 수도 있습니다만, 일단 머리가 아프고 더 쉽게 구현하는 방법이 선호됩니다.\n",
        "\n",
        "### 방법 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e094a1a2",
      "metadata": {
        "id": "e094a1a2",
        "outputId": "fda27ec9-7794-4545-8b18-a1d94261a672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(30, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "@jax.jit\n",
        "def loop_body(prev_i):\n",
        "    return prev_i + 1\n",
        "\n",
        "\n",
        "def g_inner_jitted(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        i = loop_body(i)\n",
        "    return x + i\n",
        "\n",
        "\n",
        "g_inner_jitted(10, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f48551cd",
      "metadata": {
        "id": "f48551cd"
      },
      "source": [
        "그 방법은 위와같이 wrapper 르 씌워서 jit을 적용하는 부분을 반복문의 내부 (또는 조건에 의해서 영양 받지 않는 부분)으로 제한하는겁니다.\n",
        "\n",
        "### 방법 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "33d90e3d",
      "metadata": {
        "id": "33d90e3d",
        "outputId": "378a6454-1554-4622-e8af-9eedfa9cb361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "f_jit_correct = jax.jit(f, static_argnums=0)\n",
        "print(f_jit_correct(10))\n",
        "\n",
        "g_jit_correct = jax.jit(g, static_argnames=['n'])\n",
        "print(g_jit_correct(10, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f08a1ae",
      "metadata": {
        "id": "0f08a1ae"
      },
      "source": [
        "또 다른 방법은 jax.jit 할때 static_argnums 또는 static_argnames 라는 옵션을 주는 것입니다. 이 옵션들은 해당 인자들이 정적으로 고정되어 있다고 jax에게 알려주는 역할을 합니다. 즉, 이 인자들은 컴파일 시점에 고정된 값으로 간주한 상태로 컴파일된 코드를 씁니다.\n",
        "\n",
        "그럼 조건, 즉 입력 인자가 달라지면 컴파일 된 코드가 틀리지 않냐고요? 맞습니다. 그래서 이 방법은 인자가 자주 바뀌지 않는 경우에만 씁니다. 만약 바뀌더라도, jax는 이렇게 static_argnums/static_argnames 으로 선언된 것은 나중에 변경된 것을 간단하게 리컴파일 할 수 있게 지원합니다.\n",
        "\n",
        "앞서 말씀드렸듯 jax.jit 을 데코레이터를 써서 표현하자면 다음과 같습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d1ffb0f7",
      "metadata": {
        "id": "d1ffb0f7",
        "outputId": "562cf257-23d9-4370-f4ca-9455b1a39a56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jax.jit, static_argnames=['n'])\n",
        "def g_jit_decorated(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        i += 1\n",
        "    return x + i\n",
        "\n",
        "\n",
        "print(g_jit_decorated(10, 20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e98c4f0b",
      "metadata": {
        "id": "e98c4f0b"
      },
      "source": [
        "보시다 시피 이제 partial 을 써서 jax.jit 으로 감싸되, static_argnames 라는 옵션을 주었습니다. 이 옵션은 n 이라는 인자가 정적으로 고정되어 있다고 jax에게 알려주고, partial을 통해서 그 인자가 없이 호출될 수 있도록 합니다. 이제 g_jit_correct 는 n 이라는 인자를 받지 않고도 호출될 수 있습니다.\n",
        "\n",
        "그럼 static_argnums/static_argnames 옵션을 사용하면 이렇게 조건문이 달린 함수를 자유롭게 써도 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f699bca0",
      "metadata": {
        "id": "f699bca0"
      },
      "source": [
        "## JIt 컴파일과 캐싱의 주의점\n",
        "\n",
        "jax.jit 은 컴파일된 코드를 캐싱합니다. 즉, 동일한 입력 형태에 대해 이미 컴파일된 코드가 있다면, 이를 재사용합니다. 이게 성능향상에 도움이 되기 때문에 jax를 쓴다는건 이렇게 컴파일하고 안건드리겠다는 선언이나 다름없습니다.\n",
        "\n",
        "만약 static_argnums/static_argnames 옵션을 사용하여 특정 인자를 정적으로 고정시켰다면, 해당 인자가 변경될 때마다 jax는 새로운 컴파일된 코드를 생성합니다. 예를 들어, g_jit_correct(10, 20) 를 호출할때 jax는 n=20 이라고 고정한 상태의 g_jit_correct 를 컴파일합니다. 만약 이후에 g_jit_correct(10, 30) 을 호출하면, jax는 n=30 으로 고정된 새로운 버전을 컴파일해야합니다. 이 컴파일은 시간이 오래걸리니까 이렇게 반복해서 리컴파일할때는 jit을 쓰지 않는게 좋습니다.\n",
        "\n",
        "다시말해서 어떤 방식으로든 (static_argnums/static_argnames 인자를 갖고있는 함수라던가 아니면 jax.jit 을 아예 명시적으로 for문 내에 넣는다던가) jax.jit 이 컴파일을 하는 일을 만들지 않는게 좋으며, 특히 반복문 내에서 연속적으로 부르는걸 삼가야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "df94c5ba",
      "metadata": {
        "id": "df94c5ba",
        "outputId": "6e8ec216-cb1c-4dd8-8385-9d7d937329cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jit called in a loop with partials:\n",
            "453 ms ± 18.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "jit called in a loop with lambdas:\n",
            "437 ms ± 9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "jit called in a loop with caching:\n",
            "2.63 ms ± 142 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "def unjitted_loop_body(prev_i):\n",
        "    return prev_i + 1\n",
        "\n",
        "\n",
        "def g_inner_jitted_partial(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "    # 하지마세요!\n",
        "    # 매번 partial이 다른 해쉬의 함수를 반환합니다.\n",
        "        i = jax.jit(partial(unjitted_loop_body))(i)\n",
        "    return x + i\n",
        "\n",
        "\n",
        "def g_inner_jitted_lambda(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "    # 하지마세요!\n",
        "    # lambda 또한 매번 다른 해쉬의 함수를 반환합니다.\n",
        "        i = jax.jit(lambda x: unjitted_loop_body(x))(i)\n",
        "    return x + i\n",
        "\n",
        "\n",
        "def g_inner_jitted_normal(x, n):\n",
        "    i = 0\n",
        "    while i < n:\n",
        "    # 이건 괜찮습니다!\n",
        "    # JAX가 캐싱되고 컴파일된 함수를 다시 찾을 수 있습니다.\n",
        "        i = jax.jit(unjitted_loop_body)(i)\n",
        "    return x + i\n",
        "\n",
        "\n",
        "print(\"jit called in a loop with partials:\")\n",
        "%timeit g_inner_jitted_partial(10, 20).block_until_ready()\n",
        "\n",
        "\n",
        "print(\"jit called in a loop with lambdas:\")\n",
        "%timeit g_inner_jitted_lambda(10, 20).block_until_ready()\n",
        "\n",
        "\n",
        "print(\"jit called in a loop with caching:\")\n",
        "%timeit g_inner_jitted_normal(10, 20).block_until_ready()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458e128b",
      "metadata": {
        "id": "458e128b"
      },
      "source": [
        "마지막 녀석을 제외하고는 매번 컴파일 하는 것이기 때문에(캐싱되지 않기 때문에) 시간이 훨씬 오래걸립니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0931e94f",
      "metadata": {
        "id": "0931e94f"
      },
      "source": [
        "# 그 외의 알아둬야하는 기능들\n",
        "\n",
        "## 자동 벡터화\n",
        "\n",
        "jax는 선형대수적 연산을 가속하는게 목표입니다. 그래서 벡터화(vectorization) 라는 기능을 제공합니다. 벡터화는 스칼라 연산을 벡터나 행렬 연산으로 변환하여 한 번에 여러 데이터를 처리하는 것을 의미합니다. jax에서는 jax.vmap 이라는 함수를 통해 벡터화를 지원합니다.\n",
        "\n",
        "먼저 자동 벡터화 이전에 수동 벡터화를 하는 방법에 대해서 생각해봅시다.\n",
        "\n",
        "1차원 컨볼루션을 한다고 생각해봅시다. 원래 연산은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c8b9d01d",
      "metadata": {
        "id": "c8b9d01d",
        "outputId": "59d9769b-5483-42f8-8bb0-d6af5ce4e459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([11., 20., 29.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "x = jnp.arange(5)\n",
        "w = jnp.array([2., 3., 4.])\n",
        "\n",
        "def convolve(x, w):\n",
        "    output = []\n",
        "    for i in range(1, len(x)-1):\n",
        "        output.append(jnp.dot(x[i-1:i+2], w))\n",
        "    return jnp.array(output)\n",
        "\n",
        "convolve(x, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd92b47",
      "metadata": {
        "id": "edd92b47"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "796b62e7",
      "metadata": {
        "id": "796b62e7"
      },
      "outputs": [],
      "source": [
        "xs = jnp.stack([x, x])\n",
        "ws = jnp.stack([w, w])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f4e28300",
      "metadata": {
        "id": "f4e28300",
        "outputId": "d3c8d91e-66f5-4699-8623-78303660b0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[11., 20., 29.],\n",
              "       [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def manually_batched_convolve(xs, ws):\n",
        "    output = []\n",
        "    for i in range(xs.shape[0]):\n",
        "        output.append(convolve(xs[i], ws[i]))\n",
        "    return jnp.stack(output)\n",
        "\n",
        "\n",
        "manually_batched_convolve(xs, ws)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1643fc7d",
      "metadata": {
        "id": "1643fc7d"
      },
      "source": [
        "이거는 그냥 결과는 정상적으로 나오는데 결국 연산은 jax를 사용하지 않기 때문에 속도가 느립니다. 이걸 수동 벡터화로 바꿔봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7dd88a67",
      "metadata": {
        "id": "7dd88a67",
        "outputId": "41745453-28b2-48a0-ca28-bae15caa52a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "856 µs ± 131 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "def manually_vectorized_convolve(xs, ws):\n",
        "    output = []\n",
        "\n",
        "    for i in range(1, xs.shape[-1] -1):\n",
        "        output.append(jnp.sum(xs[:, i-1:i+2] * ws, axis=1))\n",
        "    return jnp.stack(output, axis=1)\n",
        "\n",
        "\n",
        "%timeit manually_vectorized_convolve(xs, ws).block_until_ready()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b23a7ba",
      "metadata": {
        "id": "4b23a7ba"
      },
      "source": [
        "별거 없습니다. 그냥 convolve 함수에서 for 문으로 돌아가던걸 jnp.sum 을통해 직접 벡터연산으로 선언해주는겁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a081a209",
      "metadata": {
        "id": "a081a209",
        "outputId": "b10187fa-1607-44cb-c9e1-c523b8ad5552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[11., 20., 29.],\n",
              "       [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "auto_batch_convolve = jax.vmap(convolve)\n",
        "\n",
        "auto_batch_convolve(xs, ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a977b9",
      "metadata": {
        "id": "26a977b9"
      },
      "source": [
        "물론 수동으로 하면 머리아프니까.. 이렇게 수동으로 바꾸는게 아니라 jax.vmap 을 이용해서 자동으로 벡터화를 할 수도 있습니다.\n",
        "\n",
        "물론 어느 차원에 대해서 벡터화할지를 지정할 수 있습니다. 예를들어 배치차원에대해서 벡터화하는게 일반적이니까 transpose 한 데이터에대해서 vector화 할 차원을 지정하고 jax.vmap 을 적용하는 것을 생각해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "73d0ccfa",
      "metadata": {
        "id": "73d0ccfa",
        "outputId": "905a28f9-308d-4512-b9e6-7be6ff0c07a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[11., 11.],\n",
              "       [20., 20.],\n",
              "       [29., 29.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "auto_batch_convolve_v2 = jax.vmap(convolve, in_axes=1, out_axes=1)\n",
        "\n",
        "xst = jnp.transpose(xs)\n",
        "wst = jnp.transpose(ws)\n",
        "\n",
        "auto_batch_convolve_v2(xst, wst)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d81317",
      "metadata": {
        "id": "21d81317"
      },
      "source": [
        "## 그레디언트 중지\n",
        "\n",
        "torch 에서 .detach() 쓰는거 아시나요? jax에서는 jax.lax.stop_gradient를 이용해서 흘려줄 부분과 아닌 부분을 나눕니다.\n",
        "\n",
        "예를 들어 강화학습에서 TD learning 을 한다면\n",
        "\n",
        "$PE=V_\\theta(s') + r - V_\\theta(s)$\n",
        "\n",
        "이고 이때 $V_\\theta(s)$ 는 그레디언트를 흘리고 $V_\\theta(s')$ 는 흘리지 않습니다. 타겟을 정해놓고 그 타겟에 맞춰서 현재 값을 조정하는거니까요. 이럴때 jax.lax.stop_gradient 를 이용해서 $V_\\theta(s')$ 에 대해서는 그레디언트를 흘리지 않도록 할 수 있습니다.\n",
        "\n",
        "```python\n",
        "def td_loss(theta, s_tm1, r_t, s_t):\n",
        "    v_tm1 = value_fn(theta, s_tm1)\n",
        "    target = r_t + value_fn(theta, s_t)\n",
        "    return (target - v_tm1) ** 2\n",
        "\n",
        "\n",
        "td_update = jax.grad(td_loss)\n",
        "delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
        "```\n",
        "\n",
        "```python\n",
        "def td_loss_with_stop_gradient(theta, s_tm1, r_t, s_t):\n",
        "    v_tm1 = value_fn(theta, s_tm1)\n",
        "    target = r_t + value_fn(theta, s_t)\n",
        "    return (jax.lax.stop_gradient(target) - v_tm1) ** 2\n",
        "\n",
        "\n",
        "td_update = jax.grad(td_loss_with_stop_gradient)\n",
        "delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "804147c1",
      "metadata": {
        "id": "804147c1"
      },
      "source": [
        "## JAX의 난수\n",
        "\n",
        "jax의 난수에는 고려할 사항이 있습니다. 일단 알아야 할 것은 numpy 와는 다른 방식으로 난수를 생성한다는 점, 그리고 함수형으로 구현하고 병렬화하기에 이 numpy 방식의 난수생성을 그대로 갖다가 쓰기 어렵다는 점 입니다. 그래서 다른 방식으로 난수를 생성합니다.\n",
        "\n",
        "### numpy 의 난수\n",
        "\n",
        "아시다시피 numpy 는 seed를 통해서 난수를 생성하는 시드를 고정하고 거기서부터 난수를 생성합니다. 예를 들어 아래의 코드는 몇백번을 돌려도 동일한 값을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2ee24528",
      "metadata": {
        "id": "2ee24528",
        "outputId": "1b5a3bde-0636-47e7-f6cd-869ccbfd8fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5488135039273248"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "np.random.rand()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54af696d",
      "metadata": {
        "id": "54af696d"
      },
      "source": [
        "근데 한번 생각해보세요. 이걸 병렬 처리로 돌리게 되면 각각의 쓰레드에 열린 프로그램이 서로 다른 시드를 가져야만 합니다. 근데 한번 더 생각해보면 순수함수를 쓰는 jax에서 병렬화된 각 프로그램마다 다른 입력값을 넣어줄수 있을리가 없습니다. 아까본 jaxpr같이 컴파일이 되어야하는데 입력값이 결정되어서 실행하면 버튼누르듯 실행되어야하는데 서로다른 seed를 갖고 있다는것은 입력값이 다르다는 것이고 그럼 동일하게 컴파일 된 하나의 프로그램을 병렬하는게 아니라 서로다른 시드를 갖고 있는 서로다른 컴파일된 코드를 돌리는겁니다.\n",
        "\n",
        "seed가 다른걸 각각 컴파일 해서 돌려야한다는건.. 결국 오히려 컴파일 하면서 시간이 오래 걸린다는 뜻입니다. jax는 이걸 해결하기 위해서 자체적인 난수 생성 방식을 사용합니다.\n",
        "\n",
        "이때는 key라는걸 사용합니다. seed 와 비슷한데, seed는 단일 정수로 지정되어 이 시드가 있으면 난수 배열이 고정된다면, key 는 그 상위 개념으로 난수를 생성하는 시드를 여러개를 담고 있는 객체라고 생각하면됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6813227e",
      "metadata": {
        "id": "6813227e",
        "outputId": "b11c0afd-4ccd-4bb6-c6d3-e3078712f431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0 42]\n",
            "-0.028304616\n",
            "-0.028304616\n"
          ]
        }
      ],
      "source": [
        "from jax import random\n",
        "key = random.PRNGKey(42)\n",
        "print(key)\n",
        "\n",
        "print(random.normal(key))\n",
        "print(random.normal(key))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "738fce2b",
      "metadata": {
        "id": "738fce2b"
      },
      "source": [
        "이러면 별 차이 없어보이지만 더 중요한기능은 key 를 쪼개는 기능입니다. jax.random.split 이라는 함수를 통해서 key 를 여러개로 쪼갤 수 있습니다. 왜 쪼개는게 중요하냐? 병렬화 할때 같은 컴파일 코드들이 서로다른 random key 를 가지고 서로다른 난수를 생성할 수 있기 때문입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0e935216",
      "metadata": {
        "id": "0e935216",
        "outputId": "7da785a8-fc5d-4e96-ba51-5ca673aafcf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old key [ 0 42]\n",
            "    \\---SPLIT --> new key    [1832780943  270669613]\n",
            "             \\--> new subkey [  64467757 2916123636] --> normal 0.60576403\n",
            "0.60576403\n",
            "0.07592554\n"
          ]
        }
      ],
      "source": [
        "print(\"old key\", key)\n",
        "new_key, subkey = random.split(key)\n",
        "del key  # 오래된 키는 지워버리며 나중에라도 사용하지 않습니다..\n",
        "normal_sample = random.normal(subkey)\n",
        "print(r\"    \\---SPLIT --> new key   \", new_key)\n",
        "print(r\"             \\--> new subkey\", subkey, \"--> normal\", normal_sample)\n",
        "\n",
        "print(random.normal(subkey))\n",
        "del subkey  # 서브키도 사용후에 제거해야 합니다.\n",
        "key = new_key  # 만약에 한번 이 키를 다시 생성해야 한다면 new_key는 키로 사용됩니다.\n",
        "\n",
        "print(random.normal(key))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f819f41",
      "metadata": {
        "id": "7f819f41"
      },
      "source": [
        "## pytree 와 jax의 mapping\n",
        "\n",
        "jax 에서는 pytree 라는 개념을 사용합니다. pytree 는 파이썬의 기본 자료구조 (리스트, 튜플, 딕셔너리 등) 와 사용자 정의 객체를 포함하여 다양한 형태의 데이터를 트리 구조로 표현하는 방법입니다. 이 구조를 크게 이해할 필요는 없지만, 대충 jax는 함수형 언어기 때문에 이 변수를 뭉쳐서 넣기 좋은 컨테이너가 필요해서 만들었다 - 정도로 이해하고 계시면됩니다.\n",
        "\n",
        "중요한건 이 pytree 에서 mapping 이라는 기능입니다. tree_map 이라는 함수를 통해서 pytree 의 각 요소에 대해서 함수를 적용할 수 있습니다. 예를 들어, pytree에 신경망의 parameter 들이 들어있다면 이를 초기화 하기 위해서 random number 를 넣어줘야하는데 그걸 tree_map 을 통해서 쉽게 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "042eac59",
      "metadata": {
        "id": "042eac59",
        "outputId": "e1b044de-1f83-42b8-e25c-9c6ff1d69729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 'a', <object object at 0x7cd86dd84650>]   has 3 leaves: [1, 'a', <object object at 0x7cd86dd84650>]\n",
            "(1, (2, 3), ())                               has 3 leaves: [1, 2, 3]\n",
            "[1, {'k1': 2, 'k2': (3, 4)}, 5]               has 5 leaves: [1, 2, 3, 4, 5]\n",
            "{'a': 2, 'b': (2, 3)}                         has 3 leaves: [2, 2, 3]\n",
            "Array([1, 2, 3], dtype=int32)                 has 1 leaves: [Array([1, 2, 3], dtype=int32)]\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "example_trees = [\n",
        "    [1, 'a', object()],\n",
        "    (1, (2, 3), ()),\n",
        "    [1, {'k1': 2, 'k2': (3, 4)}, 5],\n",
        "    {'a': 2, 'b': (2, 3)},\n",
        "    jnp.array([1, 2, 3]),\n",
        "]\n",
        "\n",
        "for pytree in example_trees:\n",
        "  leaves = jax.tree_util.tree_leaves(pytree)\n",
        "  print(f\"{repr(pytree):<45} has {len(leaves)} leaves: {leaves}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2da8263",
      "metadata": {
        "id": "f2da8263"
      },
      "source": [
        "선언 자체를 pytree라는 특정한 클래스로 만들어서 선언하는게 아니라, 위 처럼 리스트, 튜플, 딕셔너리 등 파이썬의 기본 자료구조를 사용해서 선언하면 그걸 하나 하나 열면서 끝까지 들어가면 leaf에 해당하는 부분에 함수를 적용해야하는 구나 ~ 라는 식으로 tree_map 을 쓸 수 있습니다. 좀 더 쉬운 예제를 보자면 다음과 같습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b550579b",
      "metadata": {
        "id": "b550579b",
        "outputId": "f2e7731c-06dc-4116-978b-8eee66e26c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 4, 6], [2, 4], [2, 4, 6, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "list_of_lists = [\n",
        "    [1, 2, 3],\n",
        "    [1, 2],\n",
        "    [1, 2, 3, 4]\n",
        "]\n",
        "\n",
        "\n",
        "jax.tree_util.tree_map(lambda x: x*2, list_of_lists)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a5996d",
      "metadata": {
        "id": "c8a5996d"
      },
      "source": [
        "위 예시는 제곱하는 함수를 list of lists라는 pytree 에 적용하는 예시입니다. leaf에 적용된 걸 볼수 있습니다.\n",
        "\n",
        "아까 얘기한것처럼 신경망의 파라미터에 대해서 랜덤 초기화를 할때도 이렇게 쓸 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dc14d385",
      "metadata": {
        "id": "dc14d385",
        "outputId": "c10e4162-7e21-4f1e-f5b3-e6ebd86c56e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': Array([[-0.04002877,  0.6606242 ,  0.41818714,  0.21714671, -0.17540888,\n",
            "         0.30677566, -2.0377107 ,  1.0689473 ,  0.73738456,  1.2871753 ,\n",
            "        -0.5437603 ,  1.6119536 ,  2.0446506 ,  1.5286328 , -0.07961062,\n",
            "         1.2863609 ,  0.7882065 ,  0.30979365, -2.0485008 ,  1.0807244 ,\n",
            "        -0.341599  , -1.6678966 , -2.7420447 ,  0.50383425, -0.3409947 ,\n",
            "         1.7184497 , -1.9731419 , -0.7562774 ,  0.38279307,  2.1780643 ,\n",
            "         0.98078346, -0.14690392, -0.71036935,  0.9576821 ,  0.15676567,\n",
            "        -0.49179202,  0.6433298 ,  0.322212  , -0.7877809 , -1.2487663 ,\n",
            "        -0.3019355 ,  0.43559375, -0.2647677 ,  0.13242048,  0.52874786,\n",
            "        -1.4951242 ,  0.6316881 ,  1.7123226 ,  0.6136047 , -0.99527884,\n",
            "         0.24945721, -0.28100944, -0.30844915,  1.8176203 ,  0.5308272 ,\n",
            "        -0.25183904, -0.3391156 , -0.5795661 ,  0.5191829 ,  1.6799393 ,\n",
            "        -1.4686499 , -1.1233196 ,  1.4970272 , -0.51215523, -0.07794855,\n",
            "        -2.9027944 ,  2.1227539 , -2.068303  ,  0.1140498 , -1.1674565 ,\n",
            "        -0.16697761, -1.276143  ,  0.7973902 , -1.4772003 , -1.8894191 ,\n",
            "         2.3148358 ,  0.0600765 , -1.7524812 , -0.2639962 ,  0.8648373 ,\n",
            "        -0.3604264 ,  1.8828777 ,  1.4895254 ,  1.404079  , -2.784721  ,\n",
            "        -0.74518746, -3.2799573 ,  1.5493144 ,  3.40121   ,  1.0384781 ,\n",
            "         1.0319529 , -1.276146  , -0.78084123,  0.62293756, -0.6216436 ,\n",
            "         1.7487305 , -0.24697052,  0.2436722 ,  0.39930373, -1.415711  ,\n",
            "         0.10869596,  1.1442757 , -0.299804  , -2.8652172 ,  0.79531085,\n",
            "         1.2311149 , -0.03946102, -2.100132  , -0.9900284 , -1.4860768 ,\n",
            "         0.6203809 ,  0.9928349 , -0.55425775,  1.5123953 ,  0.19410482,\n",
            "        -0.63716906,  0.32885638,  0.49667227,  0.84758896, -0.5251403 ,\n",
            "        -0.4671669 , -0.27093166, -0.20708886,  0.684541  ,  1.9297163 ,\n",
            "        -3.0334196 ,  0.623047  ,  0.8876316 ]], dtype=float32), 'biases': Array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)}, {'weights': Array([[-0.00353808,  0.05839148,  0.03696287, ..., -0.26811895,\n",
            "         0.05507009,  0.07845629],\n",
            "       [ 0.13209836, -0.1713473 ,  0.00681951, ...,  0.15236986,\n",
            "        -0.09847563, -0.02401371],\n",
            "       [ 0.05574886, -0.01153676,  0.22067025, ...,  0.07975769,\n",
            "         0.10718396, -0.00641945],\n",
            "       ...,\n",
            "       [-0.01072687,  0.02900955, -0.10006984, ..., -0.00632536,\n",
            "         0.08659071,  0.04509991],\n",
            "       [-0.01722001,  0.20896842,  0.06429953, ...,  0.10772329,\n",
            "        -0.05944481,  0.01108218],\n",
            "       [ 0.07458356, -0.00513486,  0.09785968, ..., -0.174399  ,\n",
            "        -0.3143922 ,  0.02199904]], dtype=float32), 'biases': Array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)}, {'weights': Array([[-0.00353808],\n",
            "       [ 0.05839148],\n",
            "       [ 0.03696287],\n",
            "       [ 0.01919324],\n",
            "       [-0.0155041 ],\n",
            "       [ 0.02711539],\n",
            "       [-0.18010987],\n",
            "       [ 0.09448249],\n",
            "       [ 0.0651762 ],\n",
            "       [ 0.1137713 ],\n",
            "       [-0.04806207],\n",
            "       [ 0.14247791],\n",
            "       [ 0.18072328],\n",
            "       [ 0.13511333],\n",
            "       [-0.00703665],\n",
            "       [ 0.11369931],\n",
            "       [ 0.06966827],\n",
            "       [ 0.02738215],\n",
            "       [-0.18106359],\n",
            "       [ 0.09552344],\n",
            "       [-0.03019337],\n",
            "       [-0.14742263],\n",
            "       [-0.2423648 ],\n",
            "       [ 0.04453308],\n",
            "       [-0.03013996],\n",
            "       [ 0.15189093],\n",
            "       [-0.17440276],\n",
            "       [-0.06684611],\n",
            "       [ 0.03383445],\n",
            "       [ 0.19251552],\n",
            "       [ 0.08668983],\n",
            "       [-0.0129846 ],\n",
            "       [-0.06278837],\n",
            "       [ 0.08464794],\n",
            "       [ 0.01385626],\n",
            "       [-0.04346868],\n",
            "       [ 0.05686286],\n",
            "       [ 0.02847979],\n",
            "       [-0.06963065],\n",
            "       [-0.11037639],\n",
            "       [-0.02668758],\n",
            "       [ 0.03850141],\n",
            "       [-0.02340238],\n",
            "       [ 0.01170443],\n",
            "       [ 0.04673515],\n",
            "       [-0.13215156],\n",
            "       [ 0.05583387],\n",
            "       [ 0.15134937],\n",
            "       [ 0.05423551],\n",
            "       [-0.08797105],\n",
            "       [ 0.02204911],\n",
            "       [-0.02483796],\n",
            "       [-0.02726331],\n",
            "       [ 0.16065645],\n",
            "       [ 0.04691894],\n",
            "       [-0.02225964],\n",
            "       [-0.02997387],\n",
            "       [-0.0512269 ],\n",
            "       [ 0.04588972],\n",
            "       [ 0.14848706],\n",
            "       [-0.12981154],\n",
            "       [-0.09928837],\n",
            "       [ 0.13231976],\n",
            "       [-0.04526856],\n",
            "       [-0.00688974],\n",
            "       [-0.2565732 ],\n",
            "       [ 0.18762672],\n",
            "       [-0.1828139 ],\n",
            "       [ 0.01008067],\n",
            "       [-0.10318956],\n",
            "       [-0.01475888],\n",
            "       [-0.11279617],\n",
            "       [ 0.07048   ],\n",
            "       [-0.1305673 ],\n",
            "       [-0.16700263],\n",
            "       [ 0.2046045 ],\n",
            "       [ 0.00531006],\n",
            "       [-0.15489893],\n",
            "       [-0.02333419],\n",
            "       [ 0.07644154],\n",
            "       [-0.03185749],\n",
            "       [ 0.16642445],\n",
            "       [ 0.13165669],\n",
            "       [ 0.12410422],\n",
            "       [-0.24613689],\n",
            "       [-0.06586589],\n",
            "       [-0.28991002],\n",
            "       [ 0.13694134],\n",
            "       [ 0.30062735],\n",
            "       [ 0.09178936],\n",
            "       [ 0.09121261],\n",
            "       [-0.11279644],\n",
            "       [-0.06901727],\n",
            "       [ 0.05506042],\n",
            "       [-0.05494605],\n",
            "       [ 0.1545674 ],\n",
            "       [-0.02182932],\n",
            "       [ 0.02153778],\n",
            "       [ 0.0352938 ],\n",
            "       [-0.12513237],\n",
            "       [ 0.00960746],\n",
            "       [ 0.10114064],\n",
            "       [-0.02649918],\n",
            "       [-0.25325182],\n",
            "       [ 0.07029621],\n",
            "       [ 0.10881621],\n",
            "       [-0.00348789],\n",
            "       [-0.18562719],\n",
            "       [-0.08750697],\n",
            "       [-0.13135187],\n",
            "       [ 0.05483444],\n",
            "       [ 0.08775504],\n",
            "       [-0.04898993],\n",
            "       [ 0.13367812],\n",
            "       [ 0.0171566 ],\n",
            "       [-0.05631832],\n",
            "       [ 0.02906707],\n",
            "       [ 0.04390004],\n",
            "       [ 0.07491699],\n",
            "       [-0.04641628],\n",
            "       [-0.04129211],\n",
            "       [-0.0239472 ],\n",
            "       [-0.01830424],\n",
            "       [ 0.06050545],\n",
            "       [ 0.17056444],\n",
            "       [-0.26811895],\n",
            "       [ 0.05507009],\n",
            "       [ 0.07845629]], dtype=float32), 'biases': Array([1.], dtype=float32)}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'biases': (128,), 'weights': (1, 128)},\n",
              " {'biases': (128,), 'weights': (128, 128)},\n",
              " {'biases': (1,), 'weights': (128, 1)}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "\n",
        "def init_mlp_params(layer_widths, key):\n",
        "    params = []\n",
        "    for n_in, n_out in zip(layer_widths[:-1], layer_widths[1:]):\n",
        "        params.append(\n",
        "            dict(weights=random.normal(key, shape=(n_in, n_out)) * jnp.sqrt(2/n_in), biases=jnp.ones(shape=(n_out,))\n",
        "            )\n",
        "       )\n",
        "    return params\n",
        "\n",
        "\n",
        "key = random.PRNGKey(42)\n",
        "params = init_mlp_params([1, 128, 128, 1], key)\n",
        "\n",
        "print(params)\n",
        "\n",
        "jax.tree_util.tree_map(lambda x: x.shape, params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690e58ea",
      "metadata": {
        "id": "690e58ea"
      },
      "source": [
        "## JAX의 짱쉬운 병렬처리\n",
        "\n",
        "진짜 쉽습니다. 그냥 pmap 이라는 함수를 쓰면 됩니다. 아까 선언했던 convolve를 써봅시다. vmap 했던것과 똑같이 적용하면됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c775f86e",
      "metadata": {
        "id": "c775f86e",
        "outputId": "2c094517-0b20-4afe-b636-bd635a5afb49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([11., 20., 29.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.arange(5)\n",
        "w = np.array([2., 3., 4.])\n",
        "\n",
        "def convolve(x, w):\n",
        "  output = []\n",
        "  for i in range(1, len(x)-1):\n",
        "    output.append(jnp.dot(x[i-1:i+2], w))\n",
        "  return jnp.array(output)\n",
        "\n",
        "convolve(x, w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "919d707f",
      "metadata": {
        "id": "919d707f",
        "outputId": "4c261ecb-df68-4fef-b678-2b1796fac39c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "n_devices = jax.local_device_count()\n",
        "\n",
        "print(n_devices)\n",
        "\n",
        "xs = np.arange(5 * n_devices).reshape(-1, 5)\n",
        "ws = np.stack([w] * n_devices)\n",
        "\n",
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8792eee8",
      "metadata": {
        "id": "8792eee8",
        "outputId": "2ae1c791-55e9-4955-8834-de69ce42870d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "jax.vmap(convolve)(xs, ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "03dc1bec",
      "metadata": {
        "id": "03dc1bec",
        "outputId": "49aec0b8-a8b7-46c7-eb7a-03e31af49ac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vmap : 0.0088 sec\n",
            "pmap : 0.0596 sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "jax.vmap(convolve)(xs, ws)\n",
        "print(f\"vmap : {time.time()-start:.4f} sec\")\n",
        "start = time.time()\n",
        "jax.pmap(convolve)(xs, ws)\n",
        "print(f\"pmap : {time.time()-start:.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6b03ed",
      "metadata": {
        "id": "5e6b03ed"
      },
      "source": [
        "위의 실행시간은 디바이스 갯수에 따라서 성능에 차이가 있습니다~"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dist",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}