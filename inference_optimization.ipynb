{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNY9OOjKAUSCXh3MYvymF0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hail-members/distributed-deep-learning/blob/main/inference_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxtGwRB_MdOL",
        "outputId": "bd1150bc-f24d-488f-ff13-1d4725d9112b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Im2Col Convolution Time (Average over 5 trials): 1.034854 seconds\n",
            "Manual Convolution Time (Average over 5 trials): 1.128107 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# Helper function to measure time taken by any operation (with averaging)\n",
        "def measure_time(func, trials=5, *args):\n",
        "    total_time = 0\n",
        "    for _ in range(trials):\n",
        "        start_time = time.time()\n",
        "        result = func(*args)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        total_time += elapsed_time\n",
        "    avg_time = total_time / trials\n",
        "    return result, avg_time\n",
        "\n",
        "# Im2Col Convolution function (Manual Matrix Multiplication)\n",
        "def im2col_convolution(input_tensor, weight, kernel_size, stride=1, padding=0):\n",
        "    # Unfold input into columns (Im2col)\n",
        "    input_unfolded = F.unfold(input_tensor, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    # Reshape the weight to match input shape\n",
        "    weight_flattened = weight.view(weight.size(0), -1)\n",
        "\n",
        "    # Matrix multiplication of unfolded input and flattened weight\n",
        "    output = torch.matmul(weight_flattened, input_unfolded)\n",
        "\n",
        "    # Calculate output height and width\n",
        "    output_height = (input_tensor.size(2) + 2 * padding - kernel_size[0]) // stride + 1\n",
        "    output_width = (input_tensor.size(3) + 2 * padding - kernel_size[1]) // stride + 1\n",
        "\n",
        "    # Reshape back into output shape\n",
        "    output = output.view(input_tensor.size(0), weight.size(0), output_height, output_width)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Standard Convolution (Manual Matrix Multiplication)\n",
        "def manual_convolution(input_tensor, weight, kernel_size, stride=1, padding=0):\n",
        "    # Unfold input into columns (same as Im2Col)\n",
        "    input_unfolded = F.unfold(input_tensor, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    # Perform matrix multiplication as in Im2Col, but using the same method for fair comparison\n",
        "    weight_flattened = weight.view(weight.size(0), -1)\n",
        "    output = torch.matmul(weight_flattened, input_unfolded)\n",
        "\n",
        "    # Calculate output height and width\n",
        "    output_height = (input_tensor.size(2) + 2 * padding - kernel_size[0]) // stride + 1\n",
        "    output_width = (input_tensor.size(3) + 2 * padding - kernel_size[1]) // stride + 1\n",
        "\n",
        "    # Reshape back into output shape\n",
        "    output = output.view(input_tensor.size(0), weight.size(0), output_height, output_width)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Increase the size of the input tensor\n",
        "input_tensor = torch.randn(10, 512, 28, 28)  # Simulate a batch of 32 images of size 512x512 with 3 channels\n",
        "weight = torch.randn(1024, 512, 3, 3)  # Example convolution weight (6 output channels, 3 input channels, 3x3 kernel)\n",
        "\n",
        "# Measure the time taken for Im2Col Convolution (with 5 trials for averaging)\n",
        "_, im2col_time = measure_time(im2col_convolution, 5, input_tensor, weight, (3, 3))\n",
        "\n",
        "# Measure the time taken for Manual Convolution (with 5 trials for averaging)\n",
        "_, manual_time = measure_time(manual_convolution, 5, input_tensor, weight, (3, 3))\n",
        "\n",
        "# Output the result\n",
        "print(f\"Im2Col Convolution Time (Average over 5 trials): {im2col_time:.6f} seconds\")\n",
        "print(f\"Manual Convolution Time (Average over 5 trials): {manual_time:.6f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-place depth-wise conv"
      ],
      "metadata": {
        "id": "8-CvRSOoSjd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Helper function to measure time taken by any operation\n",
        "def measure_time(func, *args, trials=5):\n",
        "    total_time = 0\n",
        "    for _ in range(trials):\n",
        "        start_time = time.time()\n",
        "        func(*args)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        total_time += elapsed_time\n",
        "    avg_time = total_time / trials\n",
        "    return avg_time\n",
        "\n",
        "# Depth-wise convolution with in-place operations\n",
        "class InplaceDepthwiseConv(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, padding=1):\n",
        "        super(InplaceDepthwiseConv, self).__init__()\n",
        "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, padding=padding, kernel_size=kernel_size, groups=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 입력 텐서에 직접 덮어쓰는 In-place 연산\n",
        "        x = self.depthwise_conv(x).copy_(x)\n",
        "        return x\n",
        "\n",
        "# Standard Depth-wise convolution (without in-place operation)\n",
        "class StandardDepthwiseConv(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, padding=1):\n",
        "        super(StandardDepthwiseConv, self).__init__()\n",
        "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding,  groups=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise_conv(x)\n",
        "        return x\n",
        "# Input tensor (e.g., image batch of size 64x128x128 with 3 channels)\n",
        "input_tensor = torch.randn(200, 512, 28, 28)\n",
        "\n",
        "# Initialize both in-place and standard depth-wise convolution models\n",
        "inplace_conv = InplaceDepthwiseConv(in_channels=512, kernel_size=3)\n",
        "standard_conv = StandardDepthwiseConv(in_channels=512, kernel_size=3)\n",
        "\n",
        "# Measure the time for in-place depth-wise convolution\n",
        "inplace_time = measure_time(inplace_conv.forward, input_tensor)\n",
        "print(f\"In-place Depth-wise Convolution Time: {inplace_time:.6f} seconds\")\n",
        "\n",
        "# Measure the time for standard depth-wise convolution\n",
        "standard_time = measure_time(standard_conv.forward, input_tensor)\n",
        "print(f\"Standard Depth-wise Convolution Time: {standard_time:.6f} seconds\")\n",
        "\n",
        "print(\"차이가 별로 없다! 왜냐하면 이건 메모리를 덜쓰는거기 때문에...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSxGfVROOa9G",
        "outputId": "dc16a64b-c3d7-467e-9f12-47acba31a227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-place Depth-wise Convolution Time: 0.698361 seconds\n",
            "Standard Depth-wise Convolution Time: 0.816289 seconds\n",
            "차이가 별로 없다! 왜냐하면 이건 메모리를 덜쓰는거기 때문에...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "입력 텐서 $x$가 주어졌을 때,\n",
        "\n",
        "1. **Depth-wise Convolution**:\n",
        "   $$\n",
        "   x_{\\text{conv}} = W_{\\text{depthwise}} * x\n",
        "   $$\n",
        "\n",
        "2. **In-place 연산**:\n",
        "   $$\n",
        "   x_{\\text{conv}} = W_{\\text{depthwise}} * x_{\\text{conv}} \\\\\n",
        "   x_{\\text{result}} = x_{\\text{conv}} + x_{\\text{conv}}\n",
        "   $$\n",
        "\n"
      ],
      "metadata": {
        "id": "jQ44sBSgpCqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 메모리 사용량 측정 함수\n",
        "def measure_gpu_memory(func, *args, trials=5):\n",
        "    torch.cuda.reset_peak_memory_stats()  # 피크 메모리 통계 초기화\n",
        "    torch.cuda.empty_cache()  # 캐시 초기화\n",
        "\n",
        "    for _ in range(trials):\n",
        "        func(*args)\n",
        "\n",
        "    current_memory = torch.cuda.memory_allocated()  # 현재 메모리 사용량\n",
        "    peak_memory = torch.cuda.max_memory_allocated()  # 피크 메모리 사용량\n",
        "\n",
        "    return current_memory, peak_memory\n",
        "\n",
        "# 입력 텐서 생성\n",
        "input_tensor = torch.randn(1, 3, 28, 28).cuda()\n",
        "inplace_conv = InplaceDepthwiseConv(in_channels=3, kernel_size=3).cuda()\n",
        "standard_conv = StandardDepthwiseConv(in_channels=3, kernel_size=3).cuda()\n",
        "\n",
        "# Measure GPU memory usage for in-place depth-wise convolution\n",
        "current_memory, peak_memory = measure_gpu_memory(inplace_conv.forward, input_tensor)\n",
        "print(f\"In-place Depth-wise Convolution GPU Memory Usage: Current: {current_memory / 10**6:.4f} MB, Peak: {peak_memory / 10**6:.4f} MB\")\n",
        "\n",
        "# Measure GPU memory usage for standard depth-wise convolution\n",
        "current_memory, peak_memory = measure_gpu_memory(standard_conv.forward, input_tensor)\n",
        "print(f\"Standard Depth-wise Convolution GPU Memory Usage: Current: {current_memory / 10**6:.4f} MB, Peak: {peak_memory / 10**6:.4f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJRvqZ7ib5c_",
        "outputId": "396890dd-c8b9-48b8-f86f-d06974acde3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-place Depth-wise Convolution GPU Memory Usage: Current: 321.2426 MB, Peak: 321.2524 MB\n",
            "Standard Depth-wise Convolution GPU Memory Usage: Current: 321.2426 MB, Peak: 321.2524 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "왜? torch.conv2d 는 이미 이런것 고려해서 만들어졌기 때문에 메모리 차이가 나지 않는다."
      ],
      "metadata": {
        "id": "EOsKTdxsS1QW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLRWyggzVgyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}