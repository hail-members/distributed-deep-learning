{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e805597",
   "metadata": {},
   "source": [
    "# Single Node MultiGPU Training with Torchrun \n",
    "\n",
    "In the previous notebook we introduced parallel computing at HPC centers and a specific algorithm for distributed training with Pytorch, DDP.  However, there are can be many challenges that arise when utilizing multiple computational resources.  One of the biggest challenges is what happens when one of the computational resources fails during training?  In this notebook we will discuss these issues and how we set up our parallel implementation to be able to continue to run despite intermittent computational resources.  We will also combine the information in this tutorial and the previous tutorial and apply it to the MNIST Classifier we used previously.   \n",
    "\n",
    "<center>\n",
    "<img src=\"https://impanix.com/wp-content/uploads/2023/05/What-is-Fault-Tolerance-Types-and-How-To-Implement-768x461.png\" width=400 /><br>\n",
    "<b>Figure 1.</b> Fault Tolerance \n",
    "</center>\n",
    "\n",
    "\n",
    "Specifically, in this tutorial, we will cover the following material:\n",
    "- Introduce Fault Tolerance\n",
    "- Introduce Pytorch's Torchrun\n",
    "- Go over code modifications need to use torchrun to launch distributed code that is fault tolerant\n",
    "- Implement a script for training the classifier using torchrun "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80451590",
   "metadata": {},
   "source": [
    "## Fault Tolerance\n",
    "\n",
    "Leveraging multiple GPUs to train neural networks comes with many challenges.  One of the biggest is what happens when GPUs fails due to many potential issues (overheating, old system wears out, virus, etc.).  **Fault tolerance** is the ability of a system to maintain operation despite one of its components failing. One way to combat component failure is via checkpointing.  In checkpointing we periodically save the state of our application (in the case of deep learning the current weights of our model), so that if a process failure occurs we can resume our application from the previous checkpoint (See figure 2). \n",
    "\n",
    "\n",
    "<img src=\"./img/checkpointing.png\" />\n",
    "\n",
    "<b>Figure 2.</b> Visual of checkpointing.  CP refers to a point in time when a checkpoint is saved. \n",
    "\n",
    "Next, we will talk about `torchrun`, pytorch's tools for launching distributed training that will handle fault tolerance via check pointing for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470907f",
   "metadata": {},
   "source": [
    "## Using Torchrun \n",
    "\n",
    "Pytorch has a tool which automatically handles fault tolerance with checkpointing called `torchrun`.  Specifically, `torhcrun` has the following functionalities:\n",
    "\n",
    "-  worker failures are handled gracefully by restarting your workers at the previously saved checkpoint\n",
    "-  environment variables, like RANK and WORLD_SIZE, are automatically set for you.  All environment variables set by pytorch can be found [here](https://pytorch.org/docs/stable/elastic/run.html#environment-variables)\n",
    "-  number of nodes being leveraged can vary during training (elasticity)\n",
    "\n",
    "In this notebook we will introduce how to utilize environment variable automatically set in torchrun as well as how to use checkpointing.  We will not cover elasticity as it is outside the scope of this course.  To explain the functionality of the torchrun we will:\n",
    "\n",
    "1. Cover the code modifications needed using the MNIST example from the previous notebook\n",
    "2. Explain how to launch your script.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b8f4b",
   "metadata": {},
   "source": [
    "### Code Modifications with MNIST Example\n",
    "\n",
    "To utilize torchrun's functionality we will need to make some changes to the distributed scaling script we created in the previous notebook. These code changes include:\n",
    "\n",
    "1. Modify code for environment variables set by torchrun:\n",
    "    1. Remove code that sets environment variables as this done for you automatically with torchrun.\n",
    "    2. Instead, use these environment variables set by pytorch and instead of explicitly defining them.\n",
    "2. Add code for writing checkpoints and resuming training after failure\n",
    "    1. Create location to store checkpoints\n",
    "    2. Read checkpoints if they exist and resume training at epoch checkpoint was written\n",
    "    3. Write checkpoints periodically during training\n",
    "3. Remove using the mp.spawn to parallelize code and replace this with a function call, as this is done automatically by torchrun\n",
    "\n",
    "Let's highlight the listed code changes above by revisiting the MNIST example we used in previous notebook.  In order to implement these changes only two functions need to be modified, `init_distributed` and `main` functions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af9480",
   "metadata": {},
   "source": [
    "#### 1. Modify code for environment variables set by torchrun\n",
    "\n",
    "In order to use the environment variables set by torchrun we will need to make modifications to both the `init_distributed` and `main` functions as highlighted in code example below.  In summary, we removed the local_rank and world_size arguments from the `init_distributed` function and instead set these variables within the function from the environment variables set by torchrun. Additionally, we modify our main function to utilize the `local_rank` environment variable to set the device where our model should be stored as well as call the modified `init_distributed` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# A. Remove code that sets environment variables as this done for you automatically with torchrun.\n",
    "def init_distributed():    # (local_rank, world_size):\n",
    "\n",
    "    # B. Instead, use these environment variables set by pytorch and instead of explicitly defining them.\n",
    "    world_size = int(os.environ['WORLD_SIZE'])\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    torch.cuda.set_device(local_rank)                       \n",
    "    dist.init_process_group(\"nccl\",                   \n",
    "                            rank=local_rank,          \n",
    "                            world_size=world_size)    \n",
    "\n",
    "def main():\n",
    "    #####################################################################\n",
    "    # 1.B We also create the variable local_rank in our main function as well as call the new init_distributed()\n",
    "    # this will be used to assign the gpu where our model should reside as highlighted below \n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "    init_distributed()\n",
    "    ################################################\n",
    "    # .....\n",
    "    # instantiate network and set to local_rank device\n",
    "    net = Net().to(local_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1334192",
   "metadata": {},
   "source": [
    "#### 2. Add code for writing checkpoints and resuming training after failure\n",
    "\n",
    "We need to make several modifications to the main function to incorporate writing checkpoints and resuming at a checkpoint after process failure.  These modifications are highlighted below with rows of `#` and includes line by line comments to explain why each modification was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee27c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    init_distributed()\n",
    "\n",
    "    train_dataloader = prepare_data()\n",
    "\n",
    "    ################################################                                                 \n",
    "    # 2.A. Create location to store checkpoints\n",
    "\n",
    "    # Create directory for storing checkpointed model\n",
    "    model_folder_path = os.getcwd()+\"/output_model/\"          # create variable for path to folder for checkpoints\n",
    "    os.makedirs(model_folder_path,exist_ok=True)              # create directory for models if they do not exist\n",
    "    # create file name for checkpoint \n",
    "    checkpoint_file = model_folder_path+\"best_model.pt\"       # create filename for model checkpoint\n",
    "    ################################################\n",
    "\n",
    "    net = Net().to(local_rank)\n",
    "\n",
    "    #################################################\n",
    "    # 2B. Read checkpoints if they exist \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)  # load previous checkpoint\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])  # set model weights to be that of the last checkpoint\n",
    "        epoch_start = checkpoint['epoch']                      # set epoch where training should resume\n",
    "   \n",
    "    # otherwise we are starting training from the beginning at epoch 0\n",
    "    else:\n",
    "        epoch_start = 0\n",
    "    ################################################\n",
    "\n",
    "    model = DDP(net,\n",
    "            device_ids=[local_rank],                  # list of gpu that model lives on \n",
    "            output_device=local_rank,                 # where to output model\n",
    "        )\n",
    "\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    save_every = 1\n",
    "    epochs = 10\n",
    "    ###########################################################\n",
    "    # 2C. Resume training at epoch last checkpoint was written\n",
    "    for epoch in range(epoch_start, epochs):                  # note we start loop at epoch_start defined in code above\n",
    "    ###########################################################\n",
    "        train_loop(rank, train_dataloader, model, loss_fn, optimizer)\n",
    "        ###########################################################\n",
    "        # 2D. Write checkpoints periodically during training\n",
    "        if rank == 0 and epoch%save_every==0:\n",
    "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "            torch.save({                                     # save model's state_dict and current epoch periodically\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':model.module.state_dict(),\n",
    "            }, checkpoint_file)\n",
    "            print(\"Finished saving model\\n\")\n",
    "        ###########################################################\n",
    "\n",
    "    dist.destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f4789",
   "metadata": {},
   "source": [
    "You can find the entire modified script with the changes highlighted above in the file `mnist_torchrun.py`.  Next, we will learn how to run this script with `torchrun`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6887b5",
   "metadata": {},
   "source": [
    "### Launching jobs with Torchrun\n",
    "\n",
    "In order to launch our new `mnist_torchrun.py` script you can use the `torchrun` command.  There are several arguments that could pass with torchrun.  These arguments vary based on the type of job you are launching.  For example, the arguments needed for a single node job versus a multinode.  For now, we will cover the arguments needed for a single node job.  \n",
    "\n",
    "Let's start by introducing three arguments that can be helpful when launching a single node job:\n",
    "- **--standalone** : This indicates to pytorch that you are running a single machine multiworker job.  It automatically sets up a rendezvous backend that is represented by a C10d TCP store on port 29400\n",
    "- **--nnodes** : Total number of nodes being used\n",
    "- **--nproc-per-node** : number of processes per node; this is typically set to the number of GPUs on your machine(s)\n",
    "\n",
    "To launch a generic training script (YOUR_TRAINING_SCRIPT.py) on a single node with 4 GPUs you can do the following:\n",
    "\n",
    "```\n",
    "torchrun\n",
    "    --standalone\n",
    "    --nnodes=1\n",
    "    --nproc-per-node=4\n",
    "    YOUR_TRAINING_SCRIPT.py (--arg1 ... train script args...)\n",
    "```\n",
    "\n",
    "Next, let's run our MNIST training script with torchrun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be49f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.203195  [    0/60000]\n",
      "loss: 0.074431  [ 3200/60000]\n",
      "loss: 0.189091  [ 6400/60000]\n",
      "loss: 0.073738  [ 9600/60000]\n",
      "loss: 0.066978  [12800/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.062485  [    0/60000]\n",
      "loss: 0.078024  [ 3200/60000]\n",
      "loss: 0.189246  [ 6400/60000]\n",
      "loss: 0.053398  [ 9600/60000]\n",
      "loss: 0.036767  [12800/60000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.126662  [    0/60000]\n",
      "loss: 0.069352  [ 3200/60000]\n",
      "loss: 0.122379  [ 6400/60000]\n",
      "loss: 0.059098  [ 9600/60000]\n",
      "loss: 0.067286  [12800/60000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.137779  [    0/60000]\n",
      "loss: 0.018163  [ 3200/60000]\n",
      "loss: 0.138813  [ 6400/60000]\n",
      "loss: 0.054595  [ 9600/60000]\n",
      "loss: 0.033671  [12800/60000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.041862  [    0/60000]\n",
      "loss: 0.011954  [ 3200/60000]\n",
      "loss: 0.143069  [ 6400/60000]\n",
      "loss: 0.065292  [ 9600/60000]\n",
      "loss: 0.022921  [12800/60000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.081174  [    0/60000]\n",
      "loss: 0.034889  [ 3200/60000]\n",
      "loss: 0.162659  [ 6400/60000]\n",
      "loss: 0.029243  [ 9600/60000]\n",
      "loss: 0.074870  [12800/60000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.135172  [    0/60000]\n",
      "loss: 0.017945  [ 3200/60000]\n",
      "loss: 0.181934  [ 6400/60000]\n",
      "loss: 0.074838  [ 9600/60000]\n",
      "loss: 0.026501  [12800/60000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "loss: 0.052655  [    0/60000]\n",
      "loss: 0.047647  [ 3200/60000]\n",
      "loss: 0.211128  [ 6400/60000]\n",
      "loss: 0.039325  [ 9600/60000]\n",
      "loss: 0.011085  [12800/60000]\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Finished saving model\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc-per-node=4 mnist_torchrun.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e315261",
   "metadata": {},
   "source": [
    "## Exercise (optional)\n",
    "\n",
    "Modify simple linear regression script you created in previous tutorial to be able to use torchrun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 24.083977  [    0/  128]\n",
      "loss: 26.135323  [    0/  128]\n",
      "loss: 25.212147  [    0/  128]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 24.799385  [    0/  128]\n",
      "loss: 18.444149  [    0/  128]loss: 18.045048  [    0/  128]\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 16.962395  [    0/  128]\n",
      "loss: 16.770927  [    0/  128]\n",
      "loss: 13.576710  [    0/  128]loss: 13.183523  [    0/  128]\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 11.582039  [    0/  128]\n",
      "loss: 11.755295  [    0/  128]\n",
      "loss: 11.668168  [    0/  128]loss: 10.266031  [    0/  128]\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 8.568253  [    0/  128]\n",
      "loss: 8.953877  [    0/  128]\n",
      "loss: 9.378763  [    0/  128]loss: 11.899617  [    0/  128]\n",
      "\n",
      "loss: 7.603078  [    0/  128]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 8.073140  [    0/  128]\n",
      "loss: 8.063532  [    0/  128]\n",
      "loss: 9.903101  [    0/  128]\n",
      "loss: 13.486264  [    0/  128]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 8.535467  [    0/  128]\n",
      "loss: 9.112846  [    0/  128]\n",
      "loss: 11.003969  [    0/  128]\n",
      "loss: 15.417793  [    0/  128]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 9.557705  [    0/  128]\n",
      "loss: 10.002034  [    0/  128]\n",
      "loss: 11.934654  [    0/  128]loss: 16.840523  [    0/  128]\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 10.431515  [    0/  128]\n",
      "loss: 10.336411  [    0/  128]\n",
      "loss: 12.304113  [    0/  128]\n",
      "loss: 17.353153  [    0/  128]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 10.779010  [    0/  128]\n",
      "loss: 10.086973  [    0/  128]\n",
      "loss: 12.085987  [    0/  128]loss: 16.986258  [    0/  128]\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 10.567831  [    0/  128]\n",
      "loss: 9.440779  [    0/  128]\n",
      "loss: 9.971262  [    0/  128]\n",
      "loss: 11.467884  [    0/  128]\n",
      "loss: 16.010429  [    0/  128]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 8.654609  [    0/  128]\n",
      "loss: 9.230089  [    0/  128]\n",
      "loss: 10.705453  [    0/  128]\n",
      "loss: 14.764645  [    0/  128]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 7.963270  [    0/  128]\n",
      "loss: 10.031391  [    0/  128]\n",
      "loss: 8.565935  [    0/  128]loss: 13.554027  [    0/  128]\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 7.530114  [    0/  128]\n",
      "loss: 9.606644  [    0/  128]loss: 8.134575  [    0/  128]\n",
      "\n",
      "loss: 12.597019  [    0/  128]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 7.423536  [    0/  128]\n",
      "loss: 8.003799  [    0/  128]\n",
      "loss: 9.497602  [    0/  128]\n",
      "loss: 12.001453  [    0/  128]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 7.614058  [    0/  128]\n",
      "loss: 8.150340  [    0/  128]\n",
      "loss: 9.674055  [    0/  128]\n",
      "loss: 11.763142  [    0/  128]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 7.993494  [    0/  128]\n",
      "loss: 8.477062  [    0/  128]\n",
      "loss: 10.029032  [    0/  128]\n",
      "loss: 11.788194  [    0/  128]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 8.414743  [    0/  128]\n",
      "loss: 8.849287  [    0/  128]\n",
      "loss: 10.418572  [    0/  128]\n",
      "loss: 11.936691  [    0/  128]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 8.740856  [    0/  128]\n",
      "loss: 9.140112  [    0/  128]\n",
      "loss: 10.709900  [    0/  128]\n",
      "loss: 12.074926  [    0/  128]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 8.884842  [    0/  128]\n",
      "Done!\n",
      "loss: 9.267749  [    0/  128]\n",
      "Done!\n",
      "loss: 10.820014  [    0/  128]\n",
      "loss: 12.116979  [    0/  128]\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nnodes=1 --nproc_per_node=2 mnist_torchrun.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225b2ec",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "1. https://arxiv.org/abs/2006.15704\n",
    "2. https://pytorch.org/tutorials/beginner/ddp_series_theory.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21457a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_course_container",
   "language": "python",
   "name": "cnn_course_container"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
